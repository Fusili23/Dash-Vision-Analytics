# Dash Vision Analytics

ê³ ê¸‰ ì°¨ëŸ‰ ë° ë³´í–‰ì ê¶¤ì  ì˜ˆì¸¡ ì‹œìŠ¤í…œ (Advanced Vehicle & Pedestrian Trajectory Prediction System)

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš” (Project Overview)

ë¸”ë™ë°•ìŠ¤ ì˜ìƒì—ì„œ ì°¨ëŸ‰ê³¼ ë³´í–‰ìì˜ ë¯¸ë˜ ê²½ë¡œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. YOLOv11ê³¼ ByteTrackë¥¼ ì‚¬ìš©í•œ ê°ì²´ ì¶”ì , ê´‘í•™ íë¦„ ê¸°ë°˜ ìì°¨ ì›€ì§ì„ ë³´ì •, ì‹ í˜¸ë“± ë° ë„ë¡œ ì˜ì—­ ì¸ì‹ì„ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ì„ ì œê³µí•©ë‹ˆë‹¤.

A trajectory prediction system for dashcam footage featuring object tracking with YOLOv11 + ByteTrack, ego-motion compensation via optical flow, and context-aware prediction with traffic lights and semantic zones.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥ (Key Features)

- ğŸš— **ì‹¤ì‹œê°„ ê°ì²´ ì¶”ì ** - YOLOv11 + ByteTrack
- ğŸ“¹ **ìì°¨ ì›€ì§ì„ ë³´ì •** - ê´‘í•™ íë¦„ (Optical Flow) ê¸°ë°˜ Ego-motion ì¶”ì •
- ğŸš¦ **ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì˜ˆì¸¡** - ì‹ í˜¸ë“± ìƒíƒœ, ë„ë¡œ/ì¸ë„ êµ¬ë¶„
- ğŸ—ºï¸ **ì¡°ê°ë„ ë³€í™˜** - BEV (Bird's Eye View) ë³€í™˜ìœ¼ë¡œ ì‹¤ì œ ì†ë„ ê³„ì‚°
- ğŸ¨ **ë¶ˆí™•ì‹¤ì„± ì‹œê°í™”** - ë‹¤ì¤‘ ëª¨ë“œ ê¶¤ì  ì˜ˆì¸¡ (Multi-modal predictions)
- ğŸ“Š **ì´ˆë³´ì ì¹œí™”ì ** - ëª¨ë“  ì½”ë“œì— ìƒì„¸í•œ ì£¼ì„ í¬í•¨

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° (Project Structure)

```
Dash-Vision-Analytics/
â”œâ”€â”€ src/                          # ì†ŒìŠ¤ ì½”ë“œ (Source code modules)
â”‚   â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ trajectory_predictor.py  # ê¶¤ì  ì˜ˆì¸¡ (CVM, Kalman Filter)
â”‚   â”œâ”€â”€ ego_motion.py            # ìì°¨ ì›€ì§ì„ ë³´ì •
â”‚   â”œâ”€â”€ context_aware_predictor.py # ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì˜ˆì¸¡
â”‚   â”œâ”€â”€ semantic_zones.py        # ë„ë¡œ/ì¸ë„ ë§ˆìŠ¤í¬
â”‚   â””â”€â”€ bev_transformer.py       # ì¡°ê°ë„ ë³€í™˜
â”‚
â”œâ”€â”€ examples/                     # ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ (Example scripts)
â”‚   â”œâ”€â”€ test_with_prediction.py  # í†µí•© ë°ëª¨ (Main demo)
â”‚   â””â”€â”€ test.py                  # ê¸°ë³¸ ì¶”ì  (Basic tracking)
â”‚
â”œâ”€â”€ docs/                         # ë¬¸ì„œ (Documentation)
â”‚   â”œâ”€â”€ PROJECT_DOCUMENTATION.md # ê¸°ìˆ  ë¬¸ì„œ (70+ pages)
â”‚   â””â”€â”€ COMMENTS_SUMMARY.md      # ì£¼ì„ ê°€ì´ë“œ
â”‚
â”œâ”€â”€ .gitignore                    # Git ì œì™¸ íŒŒì¼
â””â”€â”€ README.md                     # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Quick Start)

### 1. ì„¤ì¹˜ (Installation)

```bash
# Clone the repository
git clone https://github.com/Fusili23/Dash-Vision-Analytics.git
cd Dash-Vision-Analytics

# Install dependencies
pip install ultralytics opencv-python numpy
```

### 2. ì‹¤í–‰ (Run)

```bash
# Run main demo with all features
python examples/test_with_prediction.py
```

**ì„¤ì • ë³€ê²½ (Configuration):**
- `examples/test_with_prediction.py` íŒŒì¼ 57-60ì¤„ì—ì„œ ê¸°ëŠ¥ ì¼œê¸°/ë„ê¸°
- Line 34: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë³€ê²½
- Line 83: ì˜ˆì¸¡ ì‹œê°„ ì¡°ì • (ê¸°ë³¸ 3ì´ˆ)

### 3. ì£¼ìš” ê¸°ëŠ¥ í† ê¸€ (Feature Toggles)

```python
ENABLE_EGO_MOTION = True        # ìì°¨ ì›€ì§ì„ ë³´ì •
ENABLE_CONTEXT_AWARE = True     # ì‹ í˜¸ë“± & ë„ë¡œ ì¸ì‹  
ENABLE_BEV_CALCULATION = True   # ì‹¤ì œ ì†ë„ ê³„ì‚° (km/h)
SHOW_OPTICAL_FLOW = False       # ê´‘í•™ íë¦„ ì‹œê°í™”
```

## ğŸ“– ì‚¬ìš© ì˜ˆì œ (Usage Examples)

### ê¸°ë³¸ ê¶¤ì  ì˜ˆì¸¡ (Basic Trajectory Prediction)

```python
from src.trajectory_predictor import KalmanFilterPredictor

predictor = KalmanFilterPredictor()

# Update with detections
for i in range(30):
    predictor.update(track_id=1, position=(x, y))

# Predict 60 frames (2 seconds @ 30fps)
predictions = predictor.predict(track_id=1, num_steps=60)
```

### Ego-Motion ë³´ì • (Ego-Motion Compensation)

```python
from src.ego_motion import EgoMotionEstimator, RelativeVelocityTracker

ego_estimator = EgoMotionEstimator(history_size=5, flow_quality='medium')
velocity_tracker = RelativeVelocityTracker()

# Estimate camera movement
ego_velocity = ego_estimator.estimate_ego_motion(frame)

# Get ground-relative velocity
velocity_tracker.update(track_id, position, ego_velocity)
actual_velocity = velocity_tracker.get_actual_velocity(track_id)
```

### ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì˜ˆì¸¡ (Context-Aware Prediction)

```python
from src.context_aware_predictor import ContextAwarePredictor, EnvironmentalContext

predictor = ContextAwarePredictor()
context = EnvironmentalContext(
    traffic_lights=[red_light],
    zone_type=SemanticZone.ROAD,
    timestamp=frame_count
)

# Predict with context
result = predictor.predict_with_context(track_id, num_steps=90, context=context)
# Returns: {'primary': [...], 'alternative': [...], 'intent': 'STOP'}
```

## ğŸ“ ì´ˆë³´ìë¥¼ ìœ„í•œ ê°€ì´ë“œ (Beginner's Guide)

ëª¨ë“  Python ì½”ë“œì— **ì´ˆë³´ì ì¹œí™”ì  ì£¼ì„**ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

- âœ… ëª¨ë“  ì¤„ ì„¤ëª…
- âœ… ì—°ì‚°ì ì˜ë¯¸ (`@`, `%`, `::`, etc.)
- âœ… Python ê°œë… ì„¤ëª… (list comprehension, f-strings, etc.)
- âœ… ë°ì´í„° êµ¬ì¡° ì„¤ëª…
- âœ… ìˆ˜í•™ ê³µì‹ í¬í•¨

ğŸ“š **ìƒì„¸ ë¬¸ì„œ**: `docs/PROJECT_DOCUMENTATION.md` (70+ í˜ì´ì§€)

## ğŸ”¬ ê¸°ìˆ  ìŠ¤íƒ (Tech Stack)

- **ê°ì²´ ê°ì§€**: YOLOv11n (Ultralytics)
- **ì¶”ì **: ByteTrack
- **ì˜ˆì¸¡**: Constant Velocity Model, Kalman Filter
- **Ego-Motion**: Dense Optical Flow (Farneback)
- **ì–¸ì–´**: Python 3.13
- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: OpenCV, NumPy

## ğŸ“Š ì„±ëŠ¥ (Performance)

| ì„¤ì • | í•´ìƒë„ | CPU FPS | GPU FPS |
|------|--------|---------|---------|
| ìµœì í™” | 640Ã—480 | 25-30 | 60+ |
| ê³ í’ˆì§ˆ | 1920Ã—1080 | 8-12 | 30+ |

## ğŸ¯ í™œìš© ì‚¬ë¡€ (Use Cases)

- ğŸš— ììœ¨ì£¼í–‰ ì—°êµ¬
- ğŸ“¹ ë¸”ë™ë°•ìŠ¤ ì˜ìƒ ë¶„ì„
- ğŸš¦ êµí†µ íë¦„ ì—°êµ¬
- âš ï¸ ì¶©ëŒ ìœ„í—˜ ì˜ˆì¸¡
- ğŸ™ï¸ ìŠ¤ë§ˆíŠ¸ì‹œí‹° ëª¨ë‹ˆí„°ë§

## ğŸ“ ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ (Key Algorithms)

### Ego-Motion ë³´ì • ê³µì‹

```
V_actual = V_perceived - V_ego
```

### BEV ì†ë„ ë³€í™˜

```
V_m/s = (V_BEV / pixels_per_meter) Ã— FPS
Speed_km/h = Speed_m/s Ã— 3.6
```

### ì •ì§€ í™•ë¥  (Stop Probability)

```
P_stop = f(distance, velocity, traffic_light_state)
```

## ğŸ› ï¸ í–¥í›„ ê°œë°œ ê³„íš (Future Enhancements)

- [ ] GPU ê°€ì† (CUDA optical flow)
- [ ] íšŒì „ ë³´ì • (rotation compensation)
- [ ] ì‹¤ì‹œê°„ ì‹œë§¨í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜
- [ ] ì¶©ëŒ ê²½ê³  ì‹œìŠ¤í…œ
- [ ] ë‹¤ì¤‘ ì¹´ë©”ë¼ ì§€ì›
- [ ] í•™ìŠµ ê¸°ë°˜ ì˜ë„ ëª¨ë¸

## ğŸ› ë¬¸ì œ í•´ê²° (Troubleshooting)

**CUDA ì—ëŸ¬**: PyTorch CUDA 12.4 ì„¤ì¹˜
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

**ëŠë¦° ì„±ëŠ¥**: `test_with_prediction.py`ì—ì„œ ê¸°ëŠ¥ ë¹„í™œì„±í™”
```python
ENABLE_BEV_CALCULATION = False
```

**ë¶€ì •í™•í•œ BEV**: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í–‰
```python
from src.bev_transformer import calibrate_bev_interactive
calibrate_bev_interactive("your_video.mp4")
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤ (License)

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.

## ğŸ‘¨â€ğŸ’» ê¸°ì—¬ì (Contributors)

- **Fusili23** - Initial work

## ğŸ™ ê°ì‚¬ì˜ ë§ (Acknowledgments)

- Ultralytics - YOLOv11
- ByteDance - ByteTrack
- OpenCV Community
- Gunnar Farneback - Optical Flow Algorithm

## ğŸ“§ ì—°ë½ì²˜ (Contact)

GitHub: [@Fusili23](https://github.com/Fusili23)

---

â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ ë³„í‘œë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!

*Last Updated: 2025-12-26*
